# =============================================================================
# SCRIPT 2: EVALUATING PRE-TRAINED KPCA MODELS (Corrected Version)
#
# Description:
# This script loads the TEST data and the pre-trained KPCA models
# generated by 'train_kpca_models.py'. For each hyperparameter combination,
# it loads the corresponding model, applies the denoising transform (without
# re-fitting), and evaluates the final AoA estimation performance.
# =============================================================================

import os
import numpy as np
import joblib
from tqdm.auto import tqdm

# --- Matplotlib Setup ---
import matplotlib
matplotlib.use('Agg')
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt

# --- Custom Project Modules ---
import espargos_0007
import cluster_utils
import CRAP
from KPCA import KPCADenoiser

# =============================================================================
# ===                      CONFIGURATION BLOCK                            ===
# =============================================================================
PARAM_GRID = {
    'n_components': [2, 4, 8, 16, 24, 26, 28, 30, 32],
    'gamma': [0.001, 0.01, 0.1, 1.0/32.0]
}
MODELS_INPUT_DIR = "kpca_trained_models"
EVALUATION_BASE_DIR = "kpca_evaluation_results"
os.makedirs(EVALUATION_BASE_DIR, exist_ok=True)
# =============================================================================


def get_unitary_rootmusic_estimator(chunksize=4, shed_coeff_ratio=0):
    I = np.eye(chunksize // 2); J = np.flip(np.eye(chunksize // 2), axis=-1)
    Q = np.asmatrix(np.block([[I, 1.0j * I], [J, -1.0j * J]]) / np.sqrt(2))
    def unitary_rootmusic(R):
        assert(len(R) == chunksize); C = np.real(Q.H @ R @ Q)
        eig_val, eig_vec = np.linalg.eigh(C); eig_val = eig_val[::-1]; eig_vec = eig_vec[:, ::-1]
        source_count = 1; En = eig_vec[:, source_count:]
        ENSQ = Q @ En @ En.T @ Q.H
        coeffs = np.asarray([np.trace(ENSQ, offset=diag) for diag in range(1, len(R))])
        coeffs = coeffs[:int(len(coeffs) * (1 - shed_coeff_ratio))]
        coeffs = np.hstack((coeffs[::-1], np.trace(ENSQ), coeffs.conj()))
        roots = np.roots(coeffs); roots = roots[abs(roots) < 1.0]
        if not roots.size > 0: return np.nan, np.nan
        largest_root = np.argmax(1 / (1.0 - np.abs(roots)))
        return np.angle(roots[largest_root]), np.abs(roots[largest_root])
    return unitary_rootmusic


# =============================================================================
# ===                   MAIN EXECUTION LOGIC WRAPPED IN A FUNCTION        ===
# =============================================================================
def main():
    """
    Main function to run the evaluation workflow.
    """
    # --- 1. Load TEST Data Only ---
    print("Loading TEST datasets...")
    test_set_robot = espargos_0007.load_dataset(espargos_0007.TEST_SET_ROBOT_FILES)
    test_set_human = espargos_0007.load_dataset(espargos_0007.TEST_SET_HUMAN_FILES)
    evaluation_datasets = test_set_robot + test_set_human

    print("Loading clutter signatures...")
    for dataset in evaluation_datasets:
        dataset['clutter_acquisitions'] = np.load(os.path.join("clutter_channel_estimates", os.path.basename(dataset['filename']) + ".npy"))

    print("Clustering test data...")
    for dataset in evaluation_datasets:
        cluster_utils.cluster_dataset(dataset)
    
    umusic = get_unitary_rootmusic_estimator(4)
    results_summary = []
    total_runs = len(PARAM_GRID['n_components']) * len(PARAM_GRID['gamma'])
    run_counter = 1

    # --- 2. Start Evaluation Loop ---
    print(f"\n--- Starting Evaluation for {total_runs} Pre-Trained Models ---")
    for n_comp in PARAM_GRID['n_components']:
        for gam in PARAM_GRID['gamma']:
            
            run_name = f"run_nc{n_comp}_g{gam:.4f}".replace('.', 'p')
            model_name = f"kpca_model_nc{n_comp}_g{gam:.4f}".replace('.', 'p') + ".joblib"
            model_path = os.path.join(MODELS_INPUT_DIR, model_name)
            
            print(f"\n--- [{run_counter}/{total_runs}] Evaluating with: {model_name} ---")

            if not os.path.exists(model_path):
                print(f"  ==> ERROR: Model file not found at {model_path}. Skipping.")
                run_counter += 1
                continue
            kpca_denoiser = joblib.load(model_path)

            run_plots_dir = os.path.join(EVALUATION_BASE_DIR, run_name, "plots")
            os.makedirs(run_plots_dir, exist_ok=True)
            
            run_maes = []
            
            for dataset in tqdm(evaluation_datasets, desc=f"Evaluating on Datasets", leave=False):
                dataset['cluster_aoa_angles'] = []
                dataset['cluster_aoa_powers'] = []
                for cluster in dataset['clusters']:
                    csi_by_transmitter_noclutter = []
                    for tx_idx, csi in enumerate(cluster['csi_freq_domain']):
                        csi_by_transmitter_noclutter.append(CRAP.remove_clutter(csi, dataset['clutter_acquisitions'][tx_idx]))
                    R = np.zeros((espargos_0007.ARRAY_COUNT, espargos_0007.COL_COUNT, espargos_0007.COL_COUNT), dtype=np.complex64)
                    for tx_csi in csi_by_transmitter_noclutter:
                        R = R + np.einsum("dbrms,dbrns->bmn", tx_csi, np.conj(tx_csi)) / tx_csi.shape[0]

                    try:
                        n_arrays, n_antennas, _ = R.shape
                        n_flat_features = n_antennas * n_antennas
                        R_flat = R.reshape(n_arrays, n_flat_features)
                        X_features_real = np.concatenate([R_flat.real, R_flat.imag], axis=1)
                        X_denoised_real_features = kpca_denoiser.transform(X_features_real)
                        denoised_real_part = X_denoised_real_features[:, :n_flat_features]
                        denoised_imag_part = X_denoised_real_features[:, n_flat_features:]
                        R_flat_denoised = denoised_real_part + 1j * denoised_imag_part
                        R_denoised = R_flat_denoised.reshape(n_arrays, n_antennas, n_antennas)
                        music_results = [umusic(R_denoised[array]) for array in range(R_denoised.shape[0])]
                    except Exception as e:
                        music_results = [(np.nan, np.nan)] * R.shape[0]

                    dataset['cluster_aoa_angles'].append(np.asarray([np.arcsin(angle_power[0] / np.pi) for angle_power in music_results]))
                    dataset['cluster_aoa_powers'].append(np.asarray([angle_power[1] for angle_power in music_results]))

                dataset['cluster_aoa_angles'] = np.asarray(dataset['cluster_aoa_angles'])
                dataset['cluster_aoa_powers'] = np.asarray(dataset['cluster_aoa_powers'])
            
            for dataset in evaluation_datasets:
                relative_pos = dataset['cluster_positions'][:, np.newaxis, :] - espargos_0007.array_positions
                normal = np.einsum("dax,ax->da", relative_pos, espargos_0007.array_normalvectors)
                right = np.einsum("dax,ax->da", relative_pos, espargos_0007.array_rightvectors)
                ideal_aoas = np.arctan2(right, normal)
                estimation_errors = dataset['cluster_aoa_angles'] - ideal_aoas
                for b in range(estimation_errors.shape[1]):
                    valid_errors = estimation_errors[:, b][~np.isnan(estimation_errors[:, b])]
                    mae = np.mean(np.abs(np.rad2deg(valid_errors))) if valid_errors.size > 0 else np.nan
                    run_maes.append(mae)
                    fig, axes = plt.subplots(1, 3, figsize=(15, 5)); norm = mcolors.Normalize(vmin=-45, vmax=45)
                    axes[0].set_title(f"KPCA+MUSIC AoA Estimates from Array {b}"); axes[1].set_title(f"Ideal AoAs from Array {b}"); axes[2].set_title(f"KPCA+MUSIC AoA Estimation Error, MAE = {mae:.2f}째")
                    im1 = axes[0].scatter(dataset["cluster_positions"][:, 0], dataset["cluster_positions"][:, 1], c=np.rad2deg(dataset["cluster_aoa_angles"][:, b]), norm=norm)
                    im2 = axes[1].scatter(dataset["cluster_positions"][:, 0], dataset["cluster_positions"][:, 1], c=np.rad2deg(ideal_aoas[:, b]), norm=norm)
                    im3 = axes[2].scatter(dataset["cluster_positions"][:, 0], dataset["cluster_positions"][:, 1], c=np.rad2deg(estimation_errors[:, b]), norm=norm)
                    for ax in axes: ax.set_xlabel("x coordinate in m"); ax.set_ylabel("y coordinate in m"); ax.axis('equal')
                    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7]); fig.colorbar(im1, cax=cbar_ax, label="Angle in Degrees")
                    plt.tight_layout(rect=[0, 0, 0.9, 1])
                    safe_dataset_basename = os.path.basename(dataset['filename']).replace(".tfrecords", "")
                    plot_filename = f"aoa_array{b}_{safe_dataset_basename}.png"
                    plt.savefig(os.path.join(run_plots_dir, plot_filename))
                    plt.close(fig)
            
            avg_mae_for_run = np.nanmean(run_maes)
            results_summary.append({'run_name': run_name, 'n_components': n_comp, 'gamma': gam, 'avg_mae': avg_mae_for_run})
            print(f"Finished evaluation for {model_name}. Average MAE: {avg_mae_for_run:.2f}째")
            run_counter += 1

    print("\n\n" + "="*60); print("=== EVALUATION COMPLETE: FINAL SUMMARY ==="); print("="*60)
    sorted_results = sorted(results_summary, key=lambda x: x['avg_mae'])
    print(f"{'Run Name':<30} | {'n_components':<15} | {'gamma':<15} | {'Avg. MAE':<10}")
    print("-"*80)
    for result in sorted_results:
        print(f"{result['run_name']:<30} | {result['n_components']:<15} | {result['gamma']:.4f}{'':<10} | {result['avg_mae']:.2f}째")
    print("-"*80)
    if sorted_results:
        best_run = sorted_results[0]
        print(f"\nBest configuration found: {best_run['run_name']}")
        print(f"==> n_components={best_run['n_components']}, gamma={best_run['gamma']:.4f} with an Average MAE of {best_run['avg_mae']:.2f}째")
    print("="*60)


# This standard Python construct ensures that the main() function is called
# only when the script is executed directly.
if __name__ == "__main__":
    main()